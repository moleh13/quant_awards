Literature Review: Graph-Guided, Regime-Aware Deep Reinforcement Learning for Crypto Portfolio Optimization
1. Deep Reinforcement Learning in Portfolio Management
Deep Reinforcement Learning (DRL) has emerged as a powerful tool for sequential decision-making in finance, enabling adaptive trading and allocation strategies in complex, volatile markets . Early foundational work by Jiang & Liang (2017) introduced the Ensemble of Identical Independent Evaluators (EIIE) framework, one of the first DRL approaches for cryptocurrency portfolio management using policy gradient methods . This pioneering study demonstrated that DRL agents could learn to dynamically rebalance crypto assets, outperforming some heuristic strategies. Building on such efforts, open-source frameworks like FinRL (Liu et al., 2020) standardized environments and algorithm implementations (e.g. DDPG, PPO, SAC) for stock and multi-asset trading . These tools lowered entry barriers and enabled wide experimentation with DRL in portfolio tasks, including crypto markets.
A key insight from the literature is that reward design and risk management are crucial for successful DRL in finance. Many DRL-based portfolio agents naively maximize returns, which can lead to excessive risk-taking and unstable performance . For example, Gu et al. (2023) observe that typical reward structures cause agents to chase high short-term returns while neglecting tail-risk, resulting in occasional large drawdowns . To address this, researchers have proposed risk-adjusted reward functions. Ying et al. (2022) integrate Conditional Value-at-Risk into the PPO algorithm (“CVaR-PPO”), explicitly constraining the agent’s policy to control downside risk . Such multi-objective or risk-aware DRL approaches have been shown to yield more balanced strategies that trade off return and volatility. Another challenge is training stability: financial time series are non-stationary and data is limited, so DRL policies can be highly sensitive to small changes in training conditions . Recent studies emphasize rigorous benchmarking and validation to avoid overfitting. For instance, Zhou et al. (2025) report on the FinRL benchmark contests, noting that policy instability and sample inefficiency remain issues, and calling for standardized evaluations across stock, crypto, and other markets . Overall, the DRL-in-finance literature has progressed from early demonstrations on single assets to sophisticated systems that handle portfolio constraints (e.g. short-selling, transaction costs) and incorporate risk-adjusted rewards to ensure robust performance in high-volatility environments .
Notably, several works apply DRL specifically to cryptocurrency portfolios, leveraging the extreme volatility as both a challenge and opportunity. Jiang et al. (2017) and subsequent crypto-focused studies confirm that DRL agents (e.g. DDPG or PPO) can exploit the persistent inefficiencies and momentum in crypto markets to achieve superior returns . However, they also highlight the importance of training techniques (like reward clipping, frequent re-training) to cope with regime shifts and bubbles in crypto prices. Choudhary et al. (2025) propose a multi-reward DRL approach that optimizes return while penalizing volatility and drawdown, showing improved Sharpe ratios on crypto portfolios (as reported in Int. J. of Computational Intelligence) . In parallel, interpretability and explainability are gaining attention: Wang et al. (2023) combine PPO with post-hoc explainers to understand the asset selection by the agent . In summary, DRL has proven to be a flexible framework for portfolio optimization, and ongoing research is refining it for financial applications by incorporating domain-specific knowledge (risk management, market constraints) to ensure stability and reliability .
2. Regime-Switching Models in Finance
Financial markets often exhibit distinct regimes – for example, bullish expansions versus bearish crashes, or high-volatility turbulence versus calm periods. Regime-switching models explicitly account for these shifts. A foundational example is the Markov Regime Switching (MRS) model introduced by Hamilton (1989), which assumes asset returns (or volatility) are driven by an unobserved state that follows a Markov chain. Such models can capture phenomena like sudden volatility shifts or changes in return distribution. Subsequent work by Ang and Bekaert (2002) showed that incorporating latent regime shifts materially alters optimal asset allocations, as investors adjust portfolios for “bull” vs “bear” regimes (e.g., reducing equity exposure in high-volatility states). In practice, regimes are often inferred with Hidden Markov Models (HMMs) applied to returns or volatility indicators. For instance, an HMM might classify market conditions into two states (expansion vs recession) based on return patterns, and allocate assets accordingly. Regime awareness has been shown to improve performance: by switching to defensive strategies in volatile regimes and aggressive strategies in calm regimes, portfolio drawdowns can be reduced .
Crypto markets likewise exhibit regime-like behavior (e.g., rapid bull runs versus crashes), spurring applications of HMMs and related filters. Pakštaitė et al. (2025) use a Bayesian two-state HMM to analyze Bitcoin price regimes, finding a fundamental shift over time . Early Bitcoin regimes (2016–2019) were driven mostly by internal factors like mining and trading volume, whereas later regimes (2020–2024) show stronger linkages to macroeconomic variables (exchange rates, stock indices) . High-volatility periods aligned with major events (regulatory news, institutional adoption), underscoring that volatility regimes in crypto can be partially explained by external shocks . This implies that detecting regime shifts (e.g., a transition from a low-volatility “steady growth” regime to a high-volatility “crash” regime) is valuable for crypto trading strategies. Indeed, Borovkova & Tsiamas (2019) demonstrate that a simple two-state HMM on Bitcoin returns can act as a trading signal – identifying bull vs. bear phases and adjusting positions to yield higher risk-adjusted returns than a static strategy.
Beyond HMMs, researchers employ Kalman filters and state-space models for regime detection and volatility tracking. Kalman filters excel at online estimation of latent variables (such as underlying volatility) and have been combined with regime models. For example, Pomorski & Gorse (2023) develop a Kalman-enhanced regime prediction model (KMRF) that detects regime switches (low vs high volatility, combined with bull/bear direction) and feeds those into a portfolio optimizer . They show that if regime changes can be detected even slightly in advance, it creates an opportunity: switching the portfolio appropriately can significantly boost profits or avoid losses . In their framework, an HMM-like model first labels market states (e.g., high-volatility bearish, low-volatility bullish, etc.), then a machine learning classifier (random forests) predicts upcoming regimes . A Kalman filter is applied to refine these predictions, and a model-predictive control optimizer rebalances the portfolio accordingly . This regime-aware portfolio (restricted to long-only for broad applicability) outperformed static benchmarks, highlighting that regime-aware strategies can enhance returns and reduce risk . Other studies similarly find that accounting for regimes improves volatility forecasting and hedging. For instance, regime-switching GARCH models (which allow volatility parameters to change across states) capture crypto’s extreme volatility better than single-regime models, yielding more accurate risk measures. Overall, the literature supports that explicitly modeling market regimes – via HMMs, MRS, or filters – leads to more adaptive and robust trading/asset allocation strategies . This provides a strong motivation to incorporate regime signals into a crypto RL agent, so that the agent can differentiate, say, a steady bull market from a turbulent crash and adjust its behavior accordingly.
3. Graph-Based Market Analysis
Financial assets are interrelated in complex networks – through correlations, causal relationships, or shared economic factors. Graph-based market analysis treats assets as nodes in a graph with edges representing some relationship (correlation, co-movement, sector linkage, etc.), enabling a rich representation of market structure beyond simple covariance matrices. Early work in this area includes Mantegna (1999), who constructed a minimum-spanning tree of stock correlations to reveal hierarchical clusters of related stocks (e.g. sectors) . Such market graphs provide insight into diversification: assets in the same cluster are highly correlated (offering less diversification benefit), whereas assets in different clusters or peripheral positions provide more risk reduction . Subsequent studies applied network science to markets of all kinds – stocks, commodities, forex, and recently cryptocurrencies – finding that network metrics (centrality, community structure, etc.) can identify key systemic assets and hidden relationships . For example, Tumminello et al. (2010) showed that during crises, correlations tighten and the market graph “small-world” structure changes, indicating regime shifts in connectivity.
In portfolio management, graph analysis has been leveraged to enhance diversification and risk management. Peralta & Zareei (2016) found that selecting stocks from different clusters of a correlation network yielded portfolios with lower volatility than those picked by classic mean-variance optimization. Expanding this idea, Pečař et al. (2021) combine linear (Pearson correlation) and nonlinear (mutual information) measures to build a multi-layer financial network, then apply community detection to select assets across communities . This network-based diversification approach was tested on both equities and crypto assets during periods including COVID-19 and the 2021 crypto crash. The results showed that for stocks, network-diversified portfolios often outperformed baseline portfolios (like index or equal-weight) in terms of higher returns and lower volatility . Specifically, selecting one representative asset from each network community produced portfolios that achieved superior Sharpe and more resilience to shocks . In crypto markets, the benefit was less clear-cut – the correlations between cryptocurrencies are highly dynamic and sometimes all assets move together during crashes. Even so, network methods helped identify subsets of cryptos that behaved differently (e.g., decentralized finance tokens vs. payment coins), which could be used to avoid over-concentration . These studies underscore that graph features can inform better portfolio construction, as they capture inter-asset relationships that static covariance or factor models might miss.
Meanwhile, the machine learning community has developed Graph Neural Networks (GNNs) to learn from graph-structured data, and these have been applied to financial problems. In stock prediction, for example, GNN-based models (e.g. GraphSAGE, Graph Attention Networks) take a graph of stocks (nodes) linked by correlations or industry relations, and output improved forecasts or signals. Feng et al. (2019) introduced a GNN for equity price movement prediction, demonstrating that incorporating a graph of stock correlations improved predictive accuracy over independent models. Recent work extends this to dynamic graphs: Kumar et al. (2024) represent global markets as a time-evolving graph (with nodes as major indices and edges weighted by volatility spillover effects) and use a Temporal Graph Attention Network to forecast volatility . Their Temporal GAT model outperforms traditional GARCH by capturing how volatility propagates through market networks (e.g., a volatility spike in one index influencing others) . This reinforces that markets are highly interconnected, and modeling those connections explicitly (via graph structures) leads to better understanding of risk. In portfolio allocation, Korangi et al. (2022) integrate GNNs directly into the optimization process: they construct a distance-correlation graph of ~500 mid-cap stocks and train a Graph Attention Network to output portfolio weights that maximize Sharpe ratio . The GAT-based portfolio consistently outperformed mean-variance and equal-weight benchmarks over 30 years, illustrating the promise of deep learning on graphs for large-scale portfolio optimization . In summary, graph-based analysis contributes two major insights for our problem: (a) it provides features (like communities, centralities, or learned embeddings) that can serve as trading signals or state inputs for an RL agent, and (b) it offers a way to enforce or evaluate diversification, ensuring the RL agent’s portfolio is not overly concentrated in highly correlated assets. Both are essential for a graph-guided crypto portfolio optimizer.
4. Integrating Graph and Regime Signals into Reinforcement Learning
The integration of graph-based features and regime information into DRL agents is an exciting frontier that aims to create context-aware, adaptive trading agents. Recent research shows that augmenting a standard RL agent (such as PPO or SAC) with additional inputs or modules for regimes/graphs can significantly improve performance in financial tasks. One approach is a two-stage architecture: first identify the market regime or graph-based factors, then feed those into the RL decision process. For example, Agakishiev et al. (2025) propose a regime-switching RL model for crypto portfolio management . In their framework, the agent’s state is expanded with regime-dependent variables. They define three market regimes for cryptocurrencies based on volatility and return quantiles (e.g. high-volatility vs low-volatility regimes) . A separate model (either an ARMA-GARCH or an LSTM) predicts the probabilities of these regimes for the next period using crypto-market metadata (like blockchain indicators) . The RL agent (a trading policy for a crypto index) is then conditioned on either the continuous regime probabilities or the most likely discrete regime . This separation of tasks – regime identification followed by regime-conditioned portfolio optimization – proved effective. The authors report that the regime-aware RL outperformed a baseline RL without regimes in terms of cumulative wealth, indicating that the agent learned to take more prudent actions during high-volatility regimes (and more aggressive positions in low-volatility periods) . An important caveat was noted: the benefits depended on regime prediction accuracy and led to additional complexity in tuning; nonetheless, the study demonstrates clear potential for investment management by combining HMM-like analysis with RL .
Another line of work integrates graph neural network modules into the RL agent to exploit inter-asset relationships. Sun et al. (2024) introduce a GraphSAGE-DRL coupled model (GRL) that improves a PPO trading agent by adding a GraphSAGE-based feature extractor . In their system, the observations include a static graph connecting stocks with sector and index information, enabling the agent to understand complex non-Euclidean relationships among assets . The GraphSAGE module learns embeddings of stocks and indices, which are fed into the PPO network as enhanced state features. This graph-informed PPO (trained on U.S. stock data) achieved higher returns and better risk metrics than the original PPO. Specifically, GRL outperformed the S&P 500 and an equal-weight portfolio in out-of-sample tests, and ablation showed that adding the graph feature extractor significantly boosted performance and robustness versus a vanilla PPO agent . Similarly, Wang et al. (2022) propose NGDRL (News Graph DRL) for stock portfolios, where a graph of news topics and stocks is used by the agent to gauge cross-sectional influences, improving trade timing. These studies underscore that incorporating relational inductive biases via GNNs helps the RL agent learn patterns like sector rotations, lead-lag effects, or contagion that would be hard to infer from independent time series.
There are also efforts in multi-agent reinforcement learning that inherently leverage graph structures. In a multi-agent setup, each asset (or group of assets) can be controlled by an individual agent, and a coordination mechanism (often graph-based) allows agents to share information or signals. For instance, Zhang et al. (2021) develop a hierarchical multi-agent system for portfolio optimization, where a top-level agent allocates capital among sectors while lower-level agents pick stocks within sectors. A communication graph links agents so that they can exchange state information, effectively making the decision process regime- and relation-aware. Such frameworks, while complex, mirror the real-world division of labor (sector specialists overseen by a portfolio manager) and have shown improved scalability to many assets. Graphs naturally model the communication channels or correlations in these multi-agent systems.
Integrating regime and graph signals into RL aligns with the goal of building a graph-guided, regime-aware crypto portfolio optimizer. By combining the insights from the above literature, one can design an RL agent that: (a) perceives market regime (e.g. via a hidden state indicating if the crypto market is in a bull, bear, or high-volatility phase), and (b) understands asset relationships (e.g. via graph-based embeddings encoding correlations or network centrality of each coin). The expected outcome, as suggested by the literature, is a more resilient and intelligent trading strategy. Such an agent would learn to reduce exposure during unfavorable regimes (as seen in regime-switching models) and to diversify or rotate holdings based on inter-asset signals (as seen in graph-based approaches). Preliminary evidence is encouraging – for example, regime-aware RL models have shown higher Sharpe ratios by avoiding bad trades in volatile periods , and GNN-augmented agents consistently outperformed their non-graph counterparts in stock trading tests . Nonetheless, the integration is non-trivial: one must carefully design the state-space, network architecture, and training procedure to blend these components. Issues like increased state dimensionality, partial observability of regimes, and training stability will need to be addressed, as noted by multiple authors . The literature surveyed provides a rich collection of methods and results to guide this development. In conclusion, the convergence of DRL, regime-switching analysis, and graph-based market modeling represents a promising path toward advanced crypto portfolio optimizers that are both regime-aware and relation-aware, capable of thriving in the highly volatile and interconnected crypto markets.
Bibliographic References:
Ang, A. & Bekaert, G. (2002). International Asset Allocation with Regime Shifts. Review of Financial Studies, 15(4), 1137-1187.


Jiang, Z. & Liang, J. (2017). Cryptocurrency Portfolio Management with Deep Reinforcement Learning. 2017 IEEE Symposium Series on Computational Intelligence (SSCI) .


Jiang, Z., Xu, D. & Liang, J. (2017). A Deep Reinforcement Learning Framework for the Financial Portfolio Management Problem. arXiv:1706.10059 .


Liu, B. et al. (2020). FinRL: A Deep Reinforcement Learning Library for Automated Stock Trading. NeurIPS Deep RL Workshop.


Gu, F. et al. (2023). MTS: A Deep Reinforcement Learning Portfolio Management Framework with Time-Awareness and Short-Selling. arXiv:2503.04143 .


Choudhary, H. et al. (2025). Risk-Adjusted Deep Reinforcement Learning for Portfolio Optimization: A Multi-reward Approach. Int. J. of Computational Intelligence (forthcoming) .


Agakishiev, I. et al. (2025). Regime Switching Forecasting for Cryptocurrencies. Digital Finance, 7(107–131) .


Pakštaitė, V. et al. (2025). Bitcoin Price Regime Shifts: A Bayesian MCMC and HMM Analysis of Macroeconomic Influence. Mathematics, 13(10), 1577 .


Pomorski, P. & Gorse, D. (2023). Multi-Period Portfolio Optimisation Using a Regime-Switching Predictive Framework. arXiv:2308.09263 .


Pečař, P. et al. (2023). Network-based Diversification of Stock and Cryptocurrency Portfolios. Applied Network Science, 8(15) .


Korangi, K. et al. (2022). Large-scale Time-Varying Portfolio Optimisation using Graph Attention Networks. (Preprint) .


Sun, Q. et al. (2024). GraphSAGE with Deep Reinforcement Learning for Financial Portfolio Optimization. Expert Systems with Applications, 238, 122027 .


Kumar, P. N. et al. (2024). Dynamic Graph Neural Networks for Enhanced Volatility Prediction in Financial Markets. arXiv:2410.16858 .


Zhou, X. et al. (2025). FinRL Contests: Benchmarking Data-Driven Financial Reinforcement Learning Agents. arXiv:2504.02281 .



